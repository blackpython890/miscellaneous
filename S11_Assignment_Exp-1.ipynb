{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S11_Assignment_Exp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEx8WRPQjvMk7QfPQR132q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ffcd38d25f3493dbc07f8009a543a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc73fb9773794802b93fedf3d9ee4abc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cbbd3a3fdc284aec9fe8ecd58158bf34",
              "IPY_MODEL_a8a00ebc65084d8dbe0331e907c1e75e"
            ]
          }
        },
        "bc73fb9773794802b93fedf3d9ee4abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbbd3a3fdc284aec9fe8ecd58158bf34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3db69282290e4fc7a7358c8604c1edc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef8fc14118e444279a790f7dc72949ce"
          }
        },
        "a8a00ebc65084d8dbe0331e907c1e75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bf7d11fd1f74627a2c135f7a8903df1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 75097736.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7f3020908fc409fae164310d943bbb8"
          }
        },
        "3db69282290e4fc7a7358c8604c1edc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef8fc14118e444279a790f7dc72949ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bf7d11fd1f74627a2c135f7a8903df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7f3020908fc409fae164310d943bbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89e80282fd86487fba97d40d6f0d080a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_285ee115d6a949e8a18f6ba2829d24de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc97c95863aa44968e6ed5eb2a22d487",
              "IPY_MODEL_dc613d5b880b4295bc3fb8632aa1f0fa"
            ]
          }
        },
        "285ee115d6a949e8a18f6ba2829d24de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc97c95863aa44968e6ed5eb2a22d487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d2551933d5344189c7299cf1432fae4",
            "_dom_classes": [],
            "description": "  6%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 122,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e01e1cfaa07d4f7da48333f29f8e046e"
          }
        },
        "dc613d5b880b4295bc3fb8632aa1f0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4324b20bda8a49209c2a5066af2ce84c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 122/2000 [02:01&lt;31:05,  1.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_394031d218a9480797e54845ddcc3280"
          }
        },
        "1d2551933d5344189c7299cf1432fae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e01e1cfaa07d4f7da48333f29f8e046e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4324b20bda8a49209c2a5066af2ce84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "394031d218a9480797e54845ddcc3280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagatabhay/miscellaneous/blob/master/S11_Assignment_Exp-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHm9xtumchsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7uouTsScAYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "3f8b51f7-49fc-4257-fc79-e6faf95b0763"
      },
      "source": [
        "!git clone https://github.com/jagatabhay/TSAI.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TSAI'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/20)\u001b[K\rremote: Counting objects:  10% (2/20)\u001b[K\rremote: Counting objects:  15% (3/20)\u001b[K\rremote: Counting objects:  20% (4/20)\u001b[K\rremote: Counting objects:  25% (5/20)\u001b[K\rremote: Counting objects:  30% (6/20)\u001b[K\rremote: Counting objects:  35% (7/20)\u001b[K\rremote: Counting objects:  40% (8/20)\u001b[K\rremote: Counting objects:  45% (9/20)\u001b[K\rremote: Counting objects:  50% (10/20)\u001b[K\rremote: Counting objects:  55% (11/20)\u001b[K\rremote: Counting objects:  60% (12/20)\u001b[K\rremote: Counting objects:  65% (13/20)\u001b[K\rremote: Counting objects:  70% (14/20)\u001b[K\rremote: Counting objects:  75% (15/20)\u001b[K\rremote: Counting objects:  80% (16/20)\u001b[K\rremote: Counting objects:  85% (17/20)\u001b[K\rremote: Counting objects:  90% (18/20)\u001b[K\rremote: Counting objects:  95% (19/20)\u001b[K\rremote: Counting objects: 100% (20/20)\u001b[K\rremote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 375 (delta 11), reused 0 (delta 0), pack-reused 355\u001b[K\n",
            "Receiving objects: 100% (375/375), 2.43 MiB | 21.08 MiB/s, done.\n",
            "Resolving deltas: 100% (176/176), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGpO659IcV5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "053db139-5062-4bba-f7bb-dbbc56d7ddb6"
      },
      "source": [
        "from TSAI.S11 import CustomResNet\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device : \",device)\n",
        "model = CustomResNet.CustomResNet().to(device)\n",
        "print(\"Model Loaded Successfully \")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device :  cuda\n",
            "Model Loaded Successfully \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG4fySQ71-5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "8ffcd38d25f3493dbc07f8009a543a31",
            "bc73fb9773794802b93fedf3d9ee4abc",
            "cbbd3a3fdc284aec9fe8ecd58158bf34",
            "a8a00ebc65084d8dbe0331e907c1e75e",
            "3db69282290e4fc7a7358c8604c1edc7",
            "ef8fc14118e444279a790f7dc72949ce",
            "7bf7d11fd1f74627a2c135f7a8903df1",
            "c7f3020908fc409fae164310d943bbb8"
          ]
        },
        "outputId": "37a773e1-3c3a-4179-8576-a2e4a3034af2"
      },
      "source": [
        "from TSAI.S11 import albumentationstransform\n",
        "albumentationstransform_train_transforms = albumentationstransform.train_transforms()\n",
        "from TSAI.S11 import dataloader\n",
        "trainloader , testloader = dataloader.datasetloader(albumentationstransform_train_transforms , batchsize = 512 , numwork = 4 )\n",
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REQUIRED LIBRARIES LOADED...\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ffcd38d25f3493dbc07f8009a543a31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "INFO : Trainloader and Testloader Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PGmLIAJ4dq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dee8ab62-b409-438e-b7ea-037e253b03db"
      },
      "source": [
        "print(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9 ,weight_decay = 0.01)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x55atJvP5Ij4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from tqdm.autonotebook import tqdm\n",
        "class LRFinder(object):\n",
        "    \"\"\"Learning rate range test.\n",
        "\n",
        "    The learning rate range test increases the learning rate in a pre-training run\n",
        "    between two boundaries in a linear or exponential manner. It provides valuable\n",
        "    information on how well the network can be trained over a range of learning rates\n",
        "    and what is the optimal learning rate.\n",
        "\n",
        "    Arguments:\n",
        "        model (torch.nn.Module): wrapped model.\n",
        "        optimizer (torch.optim.Optimizer): wrapped optimizer where the defined learning\n",
        "            is assumed to be the lower boundary of the range test.\n",
        "        criterion (torch.nn.Module): wrapped loss function.\n",
        "        device (str or torch.device, optional): a string (\"cpu\" or \"cuda\") with an\n",
        "            optional ordinal for the device type (e.g. \"cuda:X\", where is the ordinal).\n",
        "            Alternatively, can be an object representing the device on which the\n",
        "            computation will take place. Default: None, uses the same device as model.\n",
        "\n",
        "    Example:\n",
        "        >>> lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
        "        >>> lr_finder.range_test(dataloader, end_lr=100, num_iter=100)\n",
        "\n",
        "    Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
        "    fastai/lr_find: https://github.com/fastai/fastai\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, optimizer, criterion, device=None):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.history = {\"lr\": [], \"loss\": []}\n",
        "        self.best_loss = None\n",
        "\n",
        "        # Save the original state of the model and optimizer so they can be restored if\n",
        "        # needed\n",
        "        self.model_state = model.state_dict()\n",
        "        self.model_device = next(self.model.parameters()).device\n",
        "        self.optimizer_state = optimizer.state_dict()\n",
        "\n",
        "        # If device is None, use the same as the model\n",
        "        if device:\n",
        "            self.device = device\n",
        "        else:\n",
        "            self.device = self.model_device\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Restores the model and optimizer to their initial states.\"\"\"\n",
        "        self.model.load_state_dict(self.model_state)\n",
        "        self.model.to(self.model_device)\n",
        "        self.optimizer.load_state_dict(self.optimizer_state)\n",
        "\n",
        "    def range_test(\n",
        "        self,\n",
        "        train_loader,\n",
        "        val_loader=None,\n",
        "        end_lr=10,\n",
        "        num_iter=100,\n",
        "        step_mode=\"exp\",\n",
        "        smooth_f=0.05,\n",
        "        diverge_th=5,\n",
        "    ):\n",
        "        \"\"\"Performs the learning rate range test.\n",
        "\n",
        "        Arguments:\n",
        "            train_loader (torch.utils.data.DataLoader): the training set data laoder.\n",
        "            val_loader (torch.utils.data.DataLoader, optional): if None the range test\n",
        "                will only use the training loss. When given a data loader, the model is\n",
        "                evaluated after each iteration on that dataset and the evaluation loss\n",
        "                is used. Note that in this mode the test takes significantly longer but\n",
        "                generally produces more precise results. Default: None.\n",
        "            end_lr (float, optional): the maximum learning rate to test. Default: 10.\n",
        "            num_iter (int, optional): the number of iterations over which the test\n",
        "                occurs. Default: 100.\n",
        "            step_mode (str, optional): one of the available learning rate policies,\n",
        "                linear or exponential (\"linear\", \"exp\"). Default: \"exp\".\n",
        "            smooth_f (float, optional): the loss smoothing factor within the [0, 1[\n",
        "                interval. Disabled if set to 0, otherwise the loss is smoothed using\n",
        "                exponential smoothing. Default: 0.05.\n",
        "            diverge_th (int, optional): the test is stopped when the loss surpasses the\n",
        "                threshold:  diverge_th * best_loss. Default: 5.\n",
        "\n",
        "        \"\"\"\n",
        "        # Reset test results\n",
        "        self.history = {\"lr\": [], \"loss\": []}\n",
        "        self.best_loss = None\n",
        "\n",
        "        # Move the model to the proper device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Initialize the proper learning rate policy\n",
        "        if step_mode.lower() == \"exp\":\n",
        "            lr_schedule = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        elif step_mode.lower() == \"linear\":\n",
        "            lr_schedule = LinearLR(self.optimizer, end_lr, num_iter)\n",
        "        else:\n",
        "            raise ValueError(\"expected one of (exp, linear), got {}\".format(step_mode))\n",
        "\n",
        "        if smooth_f < 0 or smooth_f >= 1:\n",
        "            raise ValueError(\"smooth_f is outside the range [0, 1[\")\n",
        "\n",
        "        # Create an iterator to get data batch by batch\n",
        "        iterator = iter(train_loader)\n",
        "        for iteration in tqdm(range(num_iter)):\n",
        "            # Get a new set of inputs and labels\n",
        "            try:\n",
        "                inputs, labels = next(iterator)\n",
        "            except StopIteration:\n",
        "                iterator = iter(train_loader)\n",
        "                inputs, labels = next(iterator)\n",
        "\n",
        "            # Train on batch and retrieve loss\n",
        "            loss = self._train_batch(inputs, labels)\n",
        "            if val_loader:\n",
        "                loss = self._validate(val_loader)\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr_schedule.step()\n",
        "            self.history[\"lr\"].append(lr_schedule.get_lr()[0])\n",
        "\n",
        "            # Track the best loss and smooth it if smooth_f is specified\n",
        "            if iteration == 0:\n",
        "                self.best_loss = loss\n",
        "            else:\n",
        "                if smooth_f > 0:\n",
        "                    loss = smooth_f * loss + (1 - smooth_f) * self.history[\"loss\"][-1]\n",
        "                if loss < self.best_loss:\n",
        "                    self.best_loss = loss\n",
        "\n",
        "            # Check if the loss has diverged; if it has, stop the test\n",
        "            self.history[\"loss\"].append(loss)\n",
        "            if loss > diverge_th * self.best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "\n",
        "        print(\"Learning rate search finished. See the graph with {finder_name}.plot()\")\n",
        "    def _train_batch(self, inputs, labels):\n",
        "        # Set model to training mode\n",
        "#         self.model.train()\n",
        "\n",
        "        # Move data to the correct device\n",
        "        inputs = inputs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        # Forward pass\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        # Set model to evaluation mode and disable gradient computation\n",
        "        running_loss = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloader:\n",
        "                # Move data to the correct device\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                # Forward pass and loss computation\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        return running_loss / len(dataloader.dataset)\n",
        "\n",
        "    def plot(self, skip_start=10, skip_end=5, log_lr=True):\n",
        "        \"\"\"Plots the learning rate range test.\n",
        "\n",
        "        Arguments:\n",
        "            skip_start (int, optional): number of batches to trim from the start.\n",
        "                Default: 10.\n",
        "            skip_end (int, optional): number of batches to trim from the start.\n",
        "                Default: 5.\n",
        "            log_lr (bool, optional): True to plot the learning rate in a logarithmic\n",
        "                scale; otherwise, plotted in a linear scale. Default: True.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if skip_start < 0:\n",
        "            raise ValueError(\"skip_start cannot be negative\")\n",
        "        if skip_end < 0:\n",
        "            raise ValueError(\"skip_end cannot be negative\")\n",
        "\n",
        "        # Get the data to plot from the history dictionary. Also, handle skip_end=0\n",
        "        # properly so the behaviour is the expected\n",
        "        lrs = self.history[\"lr\"]\n",
        "        losses = self.history[\"loss\"]\n",
        "        if skip_end == 0:\n",
        "            lrs = lrs[skip_start:]\n",
        "            losses = losses[skip_start:]\n",
        "        else:\n",
        "            lrs = lrs[skip_start:-skip_end]\n",
        "            losses = losses[skip_start:-skip_end]\n",
        "\n",
        "        # Plot loss as a function of the learning rate\n",
        "        plt.plot(lrs, losses)\n",
        "        if log_lr:\n",
        "         plt.xscale(\"log\")\n",
        "         plt.xlabel(\"Learning rate\")\n",
        "         plt.ylabel(\"Loss\")\n",
        "         plt.show()\n",
        "\n",
        "class LinearLR(_LRScheduler):\n",
        "    \"\"\"Linearly increases the learning rate between two boundaries over a number of\n",
        "    iterations.\n",
        "\n",
        "    Arguments:\n",
        "        optimizer (torch.optim.Optimizer): wrapped optimizer.\n",
        "        end_lr (float, optional): the initial learning rate which is the lower\n",
        "            boundary of the test. Default: 10.\n",
        "        num_iter (int, optional): the number of iterations over which the test\n",
        "            occurs. Default: 100.\n",
        "        last_epoch (int): the index of last epoch. Default: -1.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(LinearLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr + r * (self.end_lr - base_lr) for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    \"\"\"Exponentially increases the learning rate between two boundaries over a number of\n",
        "    iterations.\n",
        "\n",
        "    Arguments:\n",
        "        optimizer (torch.optim.Optimizer): wrapped optimizer.\n",
        "        end_lr (float, optional): the initial learning rate which is the lower\n",
        "            boundary of the test. Default: 10.\n",
        "        num_iter (int, optional): the number of iterations over which the test\n",
        "            occurs. Default: 100.\n",
        "        last_epoch (int): the index of last epoch. Default: -1.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YOwK-kc4b8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "89e80282fd86487fba97d40d6f0d080a",
            "285ee115d6a949e8a18f6ba2829d24de",
            "fc97c95863aa44968e6ed5eb2a22d487",
            "dc613d5b880b4295bc3fb8632aa1f0fa",
            "1d2551933d5344189c7299cf1432fae4",
            "e01e1cfaa07d4f7da48333f29f8e046e",
            "4324b20bda8a49209c2a5066af2ce84c",
            "394031d218a9480797e54845ddcc3280"
          ]
        },
        "outputId": "5dda2b99-d647-4171-aeec-66e2ea7ce0a1"
      },
      "source": [
        "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(trainloader , end_lr = 1, num_iter = 2000 , step_mode = \"linear\")\n",
        "lr_finder.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e80282fd86487fba97d40d6f0d080a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/TSAI/S11/CustomResNet.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}